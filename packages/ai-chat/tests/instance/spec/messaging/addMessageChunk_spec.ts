/*
 *  Copyright IBM Corp. 2025
 *
 *  This source code is licensed under the Apache-2.0 license found in the
 *  LICENSE file in the root directory of this source tree.
 *
 *  @license
 */

import {
  createBaseConfig,
  renderChatAndGetInstance,
  renderChatAndGetInstanceWithStore,
  setupBeforeEach,
  setupAfterEach,
} from "../../../test_helpers";
import {
  MessageResponseTypes,
  TextItem,
  MessageResponse,
  FinalResponseChunk,
  PartialItemChunk,
  CompleteItemChunk,
  MessageRequest,
} from "../../../../src/types/messaging/Messages";
import {
  CancellationReason,
  CustomSendMessageOptions,
} from "../../../../src/types/config/MessagingConfig";
import { ChatInstance } from "../../../../src/types/instance/ChatInstance";

describe("ChatInstance.messaging.addMessageChunk", () => {
  beforeEach(setupBeforeEach);
  afterEach(setupAfterEach);

  it("should have addMessageChunk method available", async () => {
    const config = createBaseConfig();
    const instance = await renderChatAndGetInstance(config);

    expect(typeof instance.messaging.addMessageChunk).toBe("function");
  });

  it("should accept stream chunk", async () => {
    const config = createBaseConfig();
    const instance = await renderChatAndGetInstance(config);

    const chunk: PartialItemChunk = {
      streaming_metadata: {
        response_id: "msg-1",
      },
      partial_item: {
        streaming_metadata: {
          id: "chunk-1",
        },
        response_type: MessageResponseTypes.TEXT,
        text: "Hello ",
      },
    };

    await expect(
      instance.messaging.addMessageChunk(chunk),
    ).resolves.not.toThrow();
  });

  it("should return a Promise", async () => {
    const config = createBaseConfig();
    const instance = await renderChatAndGetInstance(config);

    const chunk: PartialItemChunk = {
      streaming_metadata: {
        response_id: "msg-1",
      },
      partial_item: {
        streaming_metadata: {
          id: "chunk-1",
        },
        response_type: MessageResponseTypes.TEXT,
        text: "streaming text",
      },
    };

    const result = instance.messaging.addMessageChunk(chunk);
    expect(result).toBeInstanceOf(Promise);
  });

  it("should handle multiple addMessageChunk calls and concatenate text properly in store", async () => {
    const config = createBaseConfig();
    const { instance, store } = await renderChatAndGetInstanceWithStore(config);
    const responseId = "msg-test-concat";
    const itemId = "chunk-1";

    const chunks: PartialItemChunk[] = [
      {
        streaming_metadata: { response_id: responseId },
        partial_item: {
          streaming_metadata: { id: itemId },
          response_type: MessageResponseTypes.TEXT,
          text: "Hello ",
        },
      },
      {
        streaming_metadata: { response_id: responseId },
        partial_item: {
          streaming_metadata: { id: itemId },
          response_type: MessageResponseTypes.TEXT,
          text: "world ",
        },
      },
      {
        streaming_metadata: { response_id: responseId },
        partial_item: {
          streaming_metadata: { id: itemId },
          response_type: MessageResponseTypes.TEXT,
          text: "from ",
        },
      },
      {
        streaming_metadata: { response_id: responseId },
        partial_item: {
          streaming_metadata: { id: itemId },
          response_type: MessageResponseTypes.TEXT,
          text: "Jest!",
        },
      },
    ];

    for (const chunk of chunks) {
      await instance.messaging.addMessageChunk(chunk);
    }

    const state = store.getState();
    const localItemId = `${responseId}-${itemId}`;
    const messageItem = state.allMessageItemsByID[localItemId];

    expect(messageItem).toBeDefined();
    expect(messageItem.ui_state.streamingState).toBeDefined();
    expect(messageItem.ui_state.streamingState.chunks).toHaveLength(4);
    expect(messageItem.ui_state.streamingState.isDone).toBe(false);

    const concatenatedText = messageItem.ui_state.streamingState.chunks
      .map((chunk: any) => chunk.text)
      .join("");

    expect(concatenatedText).toBe("Hello world from Jest!");
  });

  it("should handle complete streaming flow: PartialItemChunk -> CompleteItemChunk -> FinalResponseChunk", async () => {
    const config = createBaseConfig();
    const { instance, store } = await renderChatAndGetInstanceWithStore(config);
    const responseId = "msg-full-flow";
    const itemId = "chunk-1";

    // Step 1: Send partial chunks
    const partialChunks: PartialItemChunk[] = [
      {
        streaming_metadata: { response_id: responseId },
        partial_item: {
          streaming_metadata: { id: itemId },
          response_type: MessageResponseTypes.TEXT,
          text: "Streaming ",
        },
      },
      {
        streaming_metadata: { response_id: responseId },
        partial_item: {
          streaming_metadata: { id: itemId },
          response_type: MessageResponseTypes.TEXT,
          text: "text ",
        },
      },
      {
        streaming_metadata: { response_id: responseId },
        partial_item: {
          streaming_metadata: { id: itemId },
          response_type: MessageResponseTypes.TEXT,
          text: "response!",
        },
      },
    ];

    for (const chunk of partialChunks) {
      await instance.messaging.addMessageChunk(chunk);
    }

    // Verify partial chunks state
    let state = store.getState();
    const localItemId = `${responseId}-${itemId}`;
    let messageItem = state.allMessageItemsByID[localItemId];

    expect(messageItem).toBeDefined();
    expect(messageItem.ui_state.streamingState.chunks).toHaveLength(3);
    expect(messageItem.ui_state.streamingState.isDone).toBe(false);

    const partialText = messageItem.ui_state.streamingState.chunks
      .map((chunk: any) => chunk.text)
      .join("");
    expect(partialText).toBe("Streaming text response!");

    // Step 2: Send complete item chunk
    const completeItemChunk: CompleteItemChunk = {
      streaming_metadata: { response_id: responseId },
      complete_item: {
        streaming_metadata: { id: itemId },
        response_type: MessageResponseTypes.TEXT,
        text: "Complete streaming text response!",
      },
    };

    await instance.messaging.addMessageChunk(completeItemChunk);

    // Verify complete item state
    state = store.getState();
    messageItem = state.allMessageItemsByID[localItemId];

    expect(messageItem).toBeDefined();
    expect(messageItem.ui_state.streamingState.isDone).toBe(true);
    expect((messageItem.item as TextItem).text).toBe(
      "Complete streaming text response!",
    );

    // Step 3: Send final response chunk
    const finalResponseChunk: FinalResponseChunk = {
      final_response: {
        id: responseId,
        output: {
          generic: [
            {
              streaming_metadata: { id: itemId },
              response_type: MessageResponseTypes.TEXT,
              text: "Final complete streaming text response!",
            },
          ],
        },
      },
    };

    await instance.messaging.addMessageChunk(finalResponseChunk);

    // Verify final response state
    state = store.getState();
    const finalMessage = state.allMessagesByID[responseId] as MessageResponse;
    const finalMessageItem = state.allMessageItemsByID[localItemId];

    expect(finalMessage).toBeDefined();
    expect(finalMessage.id).toBe(responseId);
    expect(finalMessage.output.generic).toHaveLength(1);
    expect((finalMessage.output.generic[0] as TextItem).text).toBe(
      "Final complete streaming text response!",
    );

    expect(finalMessageItem).toBeDefined();
    expect((finalMessageItem.item as TextItem).text).toBe(
      "Final complete streaming text response!",
    );
  });

  it("should properly transition streamingState.isDone when receiving CompleteItemChunk", async () => {
    const config = createBaseConfig();
    const { instance, store } = await renderChatAndGetInstanceWithStore(config);
    const responseId = "msg-complete-test";
    const itemId = "chunk-1";

    // Send partial chunk first
    const partialChunk: PartialItemChunk = {
      streaming_metadata: { response_id: responseId },
      partial_item: {
        streaming_metadata: { id: itemId },
        response_type: MessageResponseTypes.TEXT,
        text: "Partial text",
      },
    };

    await instance.messaging.addMessageChunk(partialChunk);

    let state = store.getState();
    const localItemId = `${responseId}-${itemId}`;
    let messageItem = state.allMessageItemsByID[localItemId];

    expect(messageItem.ui_state.streamingState.isDone).toBe(false);

    // Send complete item chunk
    const completeItemChunk: CompleteItemChunk = {
      streaming_metadata: { response_id: responseId },
      complete_item: {
        streaming_metadata: { id: itemId },
        response_type: MessageResponseTypes.TEXT,
        text: "Complete text",
      },
    };

    await instance.messaging.addMessageChunk(completeItemChunk);

    state = store.getState();
    messageItem = state.allMessageItemsByID[localItemId];

    expect(messageItem.ui_state.streamingState.isDone).toBe(true);
    expect((messageItem.item as TextItem).text).toBe("Complete text");
  });

  it("should finalize message with FinalResponseChunk and update store", async () => {
    const config = createBaseConfig();
    const { instance, store } = await renderChatAndGetInstanceWithStore(config);
    const responseId = "msg-final-test";
    const itemId = "chunk-1";

    // Send partial chunk
    const partialChunk: PartialItemChunk = {
      streaming_metadata: { response_id: responseId },
      partial_item: {
        streaming_metadata: { id: itemId },
        response_type: MessageResponseTypes.TEXT,
        text: "Building response...",
      },
    };

    await instance.messaging.addMessageChunk(partialChunk);

    // Verify initial streaming state before FinalResponseChunk
    let state = store.getState();
    const localItemId = `${responseId}-${itemId}`;
    let messageItem = state.allMessageItemsByID[localItemId];

    expect(messageItem).toBeDefined();
    expect(messageItem.ui_state.streamingState.isDone).toBe(false);
    expect(messageItem.ui_state.isIntermediateStreaming).toBe(true);
    expect(messageItem.ui_state.streamingState.chunks).toHaveLength(1);

    // Send final response chunk
    const finalResponseChunk: FinalResponseChunk = {
      final_response: {
        id: responseId,
        output: {
          generic: [
            {
              streaming_metadata: { id: itemId },
              response_type: MessageResponseTypes.TEXT,
              text: "This is the final response text",
            },
          ],
        },
      },
    };

    await instance.messaging.addMessageChunk(finalResponseChunk);

    state = store.getState();
    const message = state.allMessagesByID[responseId] as MessageResponse;
    messageItem = state.allMessageItemsByID[localItemId];

    // Verify message was added to store
    expect(message).toBeDefined();
    expect(message.id).toBe(responseId);
    expect(message.output.generic).toHaveLength(1);
    expect((message.output.generic[0] as TextItem).text).toBe(
      "This is the final response text",
    );

    // Verify message item was updated with final content
    expect(messageItem).toBeDefined();
    expect((messageItem.item as TextItem).text).toBe(
      "This is the final response text",
    );

    // Verify that FinalResponseChunk achieves the same effects as CompleteItemChunk:
    // 1. Item content is replaced with final version (verified above)
    // 2. Streaming is marked as complete (no longer has streaming state)
    // 3. Intermediate streaming state is cleared
    // 4. Previous partial chunks are effectively discarded (replaced by final item)
    expect(messageItem.ui_state.streamingState).toBeUndefined();
    expect(messageItem.ui_state.isIntermediateStreaming).toBeUndefined();
  });

  it("should reuse streaming IDs when final response items match existing items but omit IDs", async () => {
    const config = createBaseConfig();
    const { instance, store } = await renderChatAndGetInstanceWithStore(config);
    const responseId = "msg-final-id-patch";
    const itemId = "chunk-1";

    await instance.messaging.addMessageChunk({
      streaming_metadata: { response_id: responseId },
      partial_item: {
        streaming_metadata: { id: itemId },
        response_type: MessageResponseTypes.TEXT,
        text: "Partial ",
      },
    });

    await instance.messaging.addMessageChunk({
      streaming_metadata: { response_id: responseId },
      complete_item: {
        streaming_metadata: { id: itemId },
        response_type: MessageResponseTypes.TEXT,
        text: "Complete text",
      },
    });

    const finalResponseChunk: FinalResponseChunk = {
      final_response: {
        id: responseId,
        output: {
          generic: [
            {
              response_type: MessageResponseTypes.TEXT,
              text: "Complete text",
            },
          ],
        },
      },
    };

    await instance.messaging.addMessageChunk(finalResponseChunk);

    const state = store.getState();
    const message = state.allMessagesByID[responseId] as MessageResponse;
    const finalItem = message.output.generic[0] as TextItem;

    expect(finalItem.streaming_metadata?.id).toBe(itemId);
    expect(state.allMessageItemsByID[`${responseId}-${itemId}`]).toBeDefined();
  });

  it("should not reuse streaming IDs when final response items differ", async () => {
    const config = createBaseConfig();
    const { instance, store } = await renderChatAndGetInstanceWithStore(config);
    const responseId = "msg-final-id-no-patch";
    const itemId = "chunk-1";

    await instance.messaging.addMessageChunk({
      streaming_metadata: { response_id: responseId },
      partial_item: {
        streaming_metadata: { id: itemId },
        response_type: MessageResponseTypes.TEXT,
        text: "Partial ",
      },
    });

    await instance.messaging.addMessageChunk({
      streaming_metadata: { response_id: responseId },
      complete_item: {
        streaming_metadata: { id: itemId },
        response_type: MessageResponseTypes.TEXT,
        text: "Complete text",
      },
    });

    const finalResponseChunk: FinalResponseChunk = {
      final_response: {
        id: responseId,
        output: {
          generic: [
            {
              response_type: MessageResponseTypes.TEXT,
              text: "Different final text",
            },
          ],
        },
      },
    };

    await instance.messaging.addMessageChunk(finalResponseChunk);

    const state = store.getState();
    const message = state.allMessagesByID[responseId] as MessageResponse;
    const finalItem = message.output.generic[0] as TextItem;

    expect(finalItem.streaming_metadata?.id).toBeUndefined();
    expect(state.allMessageItemsByID[`${responseId}-${itemId}`]).toBeDefined();
  });

  describe("Abort signal behavior during streaming", () => {
    it("should trigger abort signal with STOP_STREAMING reason when stop button is used", async () => {
      const config = createBaseConfig();
      let capturedAbortReason: string | undefined;
      let isStreaming = false;

      config.messaging = {
        customSendMessage: async (
          request: MessageRequest,
          options: CustomSendMessageOptions,
          instance: ChatInstance,
        ) => {
          isStreaming = true;

          // Listen for abort
          options.signal?.addEventListener("abort", () => {
            capturedAbortReason = options.signal?.reason;
            isStreaming = false;
          });

          const responseId = "streaming-test";
          const itemId = "chunk-1";

          // Send partial chunks
          for (let i = 0; i < 10; i++) {
            if (!isStreaming) {
              break;
            }

            await instance.messaging.addMessageChunk({
              streaming_metadata: { response_id: responseId },
              partial_item: {
                streaming_metadata: { id: itemId, cancellable: true },
                response_type: MessageResponseTypes.TEXT,
                text: `Word ${i} `,
              },
            });

            await new Promise((resolve) => setTimeout(resolve, 50));
          }

          if (isStreaming) {
            // Send final response if not cancelled
            await instance.messaging.addMessageChunk({
              final_response: {
                id: responseId,
                output: {
                  generic: [
                    {
                      streaming_metadata: { id: itemId },
                      response_type: MessageResponseTypes.TEXT,
                      text: "Complete message",
                    },
                  ],
                },
              },
            });
          }
        },
      };

      const instance = await renderChatAndGetInstance(config);

      // Start sending message
      const sendPromise = instance.send("test");

      // Wait for streaming to start
      await new Promise((resolve) => setTimeout(resolve, 100));

      // Simulate stop button click by cancelling current message
      (
        instance as any
      ).serviceManager.messageService.cancelCurrentMessageRequest();

      // Wait for message to complete/cancel
      await sendPromise.catch(() => {});

      // Verify abort was triggered with correct reason
      expect(capturedAbortReason).toBe(CancellationReason.STOP_STREAMING);
    });

    it("should handle stream_stopped flag in CompleteItemChunk when cancelled", async () => {
      const config = createBaseConfig();
      const { instance, store } =
        await renderChatAndGetInstanceWithStore(config);
      const responseId = "stopped-stream";
      const itemId = "chunk-1";

      // Send some partial chunks
      await instance.messaging.addMessageChunk({
        streaming_metadata: { response_id: responseId },
        partial_item: {
          streaming_metadata: { id: itemId, cancellable: true },
          response_type: MessageResponseTypes.TEXT,
          text: "Partial ",
        },
      });

      await instance.messaging.addMessageChunk({
        streaming_metadata: { response_id: responseId },
        partial_item: {
          streaming_metadata: { id: itemId, cancellable: true },
          response_type: MessageResponseTypes.TEXT,
          text: "text ",
        },
      });

      // Send complete item with stream_stopped flag
      await instance.messaging.addMessageChunk({
        streaming_metadata: { response_id: responseId },
        complete_item: {
          streaming_metadata: { id: itemId, stream_stopped: true },
          response_type: MessageResponseTypes.TEXT,
          text: "Partial text",
        },
      });

      // Verify the item was marked as stopped
      const state = store.getState();
      const localItemId = `${responseId}-${itemId}`;
      const messageItem = state.allMessageItemsByID[localItemId];

      expect(messageItem).toBeDefined();
      expect(messageItem.ui_state.streamingState.isDone).toBe(true);
      expect((messageItem.item as TextItem).text).toBe("Partial text");
    });

    it("should verify abort signal is passed to customSendMessage", async () => {
      const config = createBaseConfig();
      let signalReceived = false;
      let signalIsAbortSignal = false;

      config.messaging = {
        customSendMessage: async (
          request: MessageRequest,
          options: CustomSendMessageOptions,
          _instance: ChatInstance,
        ) => {
          signalReceived = options.signal !== undefined;
          signalIsAbortSignal = options.signal instanceof AbortSignal;
        },
      };

      const instance = await renderChatAndGetInstance(config);
      await instance.send("test");

      expect(signalReceived).toBe(true);
      expect(signalIsAbortSignal).toBe(true);
    });
  });
});
